{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import label, binary_dilation, binary_erosion\n",
    "from scipy.ndimage import find_objects\n",
    "import os.path as op\n",
    "import mne\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with results of SWR detection per patient\n",
    "detected_SWRs = {\"PatientX\" : \"file path\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with hippocampal contacts per peatient\n",
    "hippocampus_electrodes = {\"PatientX\" : ['EEG001']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionayr of recording durations per patient\n",
    "recording_durations = { \"PatientX\" : 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of raw recoridng per patient\n",
    "raw_files = {\"PatientX\" : \"file path\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters \n",
    "eeg_fs = 1000 #eeg samplig frequency\n",
    "min_gap = 50 #minim gap between SWR events included in ms\n",
    "no_of_epochs = 30 #no of desired epochs\n",
    "\n",
    "#save path\n",
    "epochs_save_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for patient_id, electrodes in hippocampus_electrodes.items():\n",
    "    df = pd.read_csv(detected_SWRs[patient_id])\n",
    "    df = df[df['Channel'].isin(electrodes)]\n",
    "    if df.empty:\n",
    "        print(f\"No hippocampal channels found for {patient_id}\")\n",
    "        continue\n",
    "    SWR_times = (df['rippleTime'].apply(lambda x: eval(x, {'array': np.array}))).tolist()\n",
    "    \n",
    "    duration = recording_durations[patient_id]\n",
    "    eeg_no_samples = int(duration * eeg_fs)\n",
    "    no_channels = len(df)\n",
    "\n",
    "    #covert to a binary array with the lenght of recording(number of samples) where 1 represents a timepoint (sample) where SWR is detected\n",
    "    SWR_array = np.zeros((no_channels, eeg_no_samples), dtype=int)\n",
    "    for channel, times in enumerate(SWR_times):\n",
    "        if not times or all(len(t) == 0 for t in times):\n",
    "            ripple_time_value = df.iloc[channel]['rippleTime'] \n",
    "            print(f\"Skipping empty SWR_times for channel index {channel} in patient {patient_id}\")\n",
    "            continue\n",
    "        channel_SWR_times = np.hstack(times)\n",
    "        channel_SWR_idx = np.round((channel_SWR_times * eeg_fs), 0).astype(int)\n",
    "        SWR_array[channel, channel_SWR_idx] = 1\n",
    "\n",
    "    #sum across the hippocampal contacts\n",
    "    SWR_sum = np.sum(SWR_array, axis = 0)\n",
    "\n",
    "    #get regions where SWRs were detected\n",
    "    valid_regions = (SWR_sum >= 1)\n",
    "    #dialate and erode to merge neighbouring regions\n",
    "    min_duration_samples = int(10)\n",
    "    structure_element = np.ones(min_duration_samples)\n",
    "    valid_regions = binary_dilation(valid_regions, structure=structure_element)\n",
    "    valid_regions = binary_erosion(valid_regions, structure=structure_element)\n",
    "    #need to label connected valid regions\n",
    "    labeled_regions, num_regions = label(valid_regions)\n",
    "    slices = find_objects(labeled_regions)\n",
    "    #compoute region properties\n",
    "    region_peaks = []\n",
    "    for region in slices:\n",
    "        start = region[0].start\n",
    "        end = region[0].stop\n",
    "        region_signal = SWR_sum[start:end]\n",
    "        peak_relative = np.argmax(region_signal)\n",
    "        peak_sample = start + peak_relative\n",
    "        peak_time_sec = peak_sample / eeg_fs\n",
    "        peak_value = SWR_sum[peak_sample]\n",
    "\n",
    "        region_peaks.append({\n",
    "            \"start_sample\": start,\n",
    "            \"end_sample\": end,\n",
    "            \"peak_sample\": peak_sample,\n",
    "            \"peak_time_sec\": peak_time_sec,\n",
    "            \"peak_value\": SWR_sum[peak_sample],\n",
    "            \"duration_ms\": (end - start) / eeg_fs * 1000\n",
    "        })\n",
    "\n",
    "    print(f\"{patient_id}: Found {len(region_peaks)} SWR events.\")\n",
    "    df_regions = pd.DataFrame(region_peaks)\n",
    "  \n",
    "    \n",
    "    #get regions of no SWRs    \n",
    "    valid_no_regions = (SWR_sum == 0)\n",
    "    #dialate and erode to merge neighbouring regions\n",
    "    min_duration_samples = int(10)\n",
    "    structure_element = np.ones(min_duration_samples)\n",
    "    valid_no_regions = binary_dilation(valid_no_regions, structure=structure_element)\n",
    "    valid_no_regions = binary_erosion(valid_no_regions, structure=structure_element)\n",
    "    \n",
    "    labeled_low_regions, num_low_regions = label(valid_no_regions)\n",
    "    low_slices = find_objects(labeled_low_regions)\n",
    "\n",
    "    low_regions = []\n",
    "    for low_region in low_slices:\n",
    "        start = low_region[0].start\n",
    "        end = low_region[0].stop\n",
    "        duration_ms = (end - start) / eeg_fs * 1000\n",
    "        midpoint_sample = (start + end) // 2 \n",
    "\n",
    "        low_regions.append({\n",
    "        \"start_sample\": start,\n",
    "        \"end_sample\": end,\n",
    "        \"midpoint_sample\": midpoint_sample,\n",
    "        \"duration_ms\": duration_ms})\n",
    "\n",
    "    print(f\"{patient_id}: Found {len(low_regions)} no SWR events.\")\n",
    "\n",
    "\n",
    "    #make the MNE epochs\n",
    "    #improt raw\n",
    "    raw = mne.io.read_raw_fif(raw_files[patient_id], preload = True)\n",
    "    #notch filter\n",
    "    notch_freqs = [50, 100, 150]\n",
    "    raw = raw.notch_filter(freqs=notch_freqs, notch_widths=4)\n",
    "    raw_selected = raw.copy()\n",
    "    data = raw_selected.get_data()\n",
    "    info = raw_selected.info\n",
    "    data_elect = mne.io.RawArray(data, info)\n",
    "\n",
    "    #events array for SWRs\n",
    "    if len(df_regions) < no_of_epochs:\n",
    "        print(f\"{patient_id}: Less than {no_of_epochs} SWRs regions detected. Using all {len(df_regions)} available regions.\")\n",
    "    else:\n",
    "        df_regions = df_regions.sort_values(\"peak_value\", ascending = False).head(no_of_epochs)\n",
    "\n",
    "    df_regions = df_regions.sort_values(\"peak_sample\") #to enusre chronological order\n",
    "    events = []\n",
    "    last_event = -min_gap\n",
    "    used_swr_regions = 0\n",
    "    for row in df_regions.itertuples():\n",
    "        peak_sample = row.peak_sample\n",
    "        if peak_sample >= last_event + min_gap:\n",
    "            events.append([peak_sample, 0, 1])\n",
    "            last_event = peak_sample\n",
    "            used_swr_regions += 1\n",
    "\n",
    "    if used_swr_regions < no_of_epochs:\n",
    "     print(f\"{patient_id}: Only {used_swr_regions} SWR epochs could be used after applying min_gap constraint.\")\n",
    "    \n",
    "    #events for no SWRs\n",
    "    if len(low_regions) < no_of_epochs:\n",
    "        print(f\"{patient_id}: Less than {no_of_epochs} low-SWR regions detected. Using all {len(low_regions)} available regions.\")\n",
    "        random_low_regions = low_regions\n",
    "    else:   \n",
    "        random_low_regions = random.sample(low_regions, no_of_epochs)\n",
    "        random_low_regions = sorted(random_low_regions, key=lambda x: x[\"midpoint_sample\"]) \n",
    "\n",
    "    for region in random_low_regions:\n",
    "        midpoint_sample = region[\"midpoint_sample\"]\n",
    "        events.append([midpoint_sample, 0, 2])\n",
    "    \n",
    "    events = np.array(events, dtype=int)\n",
    "    if len(events) == 0:\n",
    "       print(f\"{patient_id}: No valid events found for epoching.\")\n",
    "       continue\n",
    "\n",
    "\n",
    "    #set picks to either picks = hippocampus_electrodes[patient_id] for ieeg electrdoes, or pick = ['mag', 'grad'] for MEG sensors\n",
    "    high_epochs = mne.Epochs(data_elect, events, event_id=1, tmin=-1, tmax=1, picks = hippocampus_electrodes[patient_id], preload=True)\n",
    "    low_epochs = mne.Epochs(data_elect, events, event_id=2, tmin=-1, tmax=1, picks = hippocampus_electrodes[patient_id], preload=True)\n",
    "    all_epochs = mne.Epochs(data_elect, events, event_id= [1, 2], tmin=-1, tmax=1, picks = hippocampus_electrodes[patient_id], preload=True)\n",
    "   \n",
    "   \n",
    "    #save\n",
    "    high_epoch_filename = op.join(epochs_save_path, f\"{patient_id}_high_SWR_epochs.fif\")\n",
    "    low_epoch_filename = op.join(epochs_save_path, f\"{patient_id}_low_SWR_epochs.fif\")\n",
    "    all_epoch_filename = op.join(epochs_save_path, f\"{patient_id}_all_SWR_epochs.fif\")\n",
    "    high_epochs.save(high_epoch_filename, overwrite=True)\n",
    "    low_epochs.save(low_epoch_filename, overwrite=True)\n",
    "    all_epochs.save(all_epoch_filename, overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
